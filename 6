import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

# Load Fashion MNIST dataset
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

# Visualize a sample image
plt.imshow(X_train[0], cmap="gray")

# Check dataset shapes
X_train.shape
X_test.shape

# Visualize a random image
i = random.randint(1, 60000)
plt.imshow(X_train[i], cmap='gray')
label = y_train[i]
label

# Grid visualization of multiple images
W_grid = 15
L_grid = 15
fig, axes = plt.subplots(L_grid, W_grid, figsize=(17, 17))
axes = axes.ravel()
n_training = len(X_train)
for i in np.arange(0, W_grid * L_grid):
    index = np.random.randint(0, n_training)
    axes[i].imshow(X_train[index])
    axes[i].set_title(y_train[index], fontsize=8)
    axes[i].axis('off')
plt.subplots_adjust(hspace=0.4)

# Normalize the images
X_train = X_train / 255
X_test = X_test / 255

# Add noise to training data
noise_factor = 0.3
noise_dataset = []
for img in X_train:
    noisy_image = img + noise_factor * np.random.randn(*img.shape)
    noisy_image = np.clip(noisy_image, 0., 1.)
    noise_dataset.append(noisy_image)
noise_dataset = np.array(noise_dataset)
noise_dataset.shape
plt.imshow(noise_dataset[22], cmap="gray")

# Add noise to test data
noise_test_set = []
for img in X_test:
    noisy_image = img + noise_factor * np.random.randn(*img.shape)
    noisy_image = np.clip(noisy_image, 0., 1.)
    noise_test_set.append(noisy_image)
noise_test_set = np.array(noise_test_set)
noise_test_set.shape

# Build the autoencoder
autoencoder = tf.keras.models.Sequential()
autoencoder.add(tf.keras.layers.Conv2D(16, 3, strides=2, padding="same", input_shape=(28, 28, 1)))
autoencoder.add(tf.keras.layers.Conv2D(8, 3, strides=2, padding="same"))
autoencoder.add(tf.keras.layers.Conv2D(8, 3, strides=1, padding="same"))
autoencoder.add(tf.keras.layers.Conv2DTranspose(16, 3, strides=2, padding="same"))
autoencoder.add(tf.keras.layers.Conv2DTranspose(1, 3, strides=2, activation='sigmoid', padding="same"))

# Compile the model
autoencoder.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))
autoencoder.summary()

# Train the autoencoder
autoencoder.fit(noise_dataset.reshape(-1, 28, 28, 1),
                X_train.reshape(-1, 28, 28, 1),
                epochs=10,
                batch_size=200,
                validation_data=(noise_test_set.reshape(-1, 28, 28, 1), X_test.reshape(-1, 28, 28, 1)))

# Evaluate the model
evaluation = autoencoder.evaluate(noise_test_set.reshape(-1, 28, 28, 1), X_test.reshape(-1, 28, 28, 1))
print('Test Accuracy : {:.3f}'.format(evaluation))

# Predict on test set
predicted = autoencoder.predict(noise_test_set[:10].reshape(-1, 28, 28, 1))
predicted.shape

# Plot noisy vs denoised images
fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20, 4))
for images, row in zip([noise_test_set[:10], predicted], axes):
    for img, ax in zip(images, row):
        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
